{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CartPoleDQN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Megacity1/CartpoleDQN/blob/main/Week%203%20Deep%20RL%202/CartPoleDQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKK5DA390wRe"
      },
      "source": [
        "# Deep Q Network (DQN) for CartPole Using Boltzmann Q Policy\n",
        "This exercise implements a DQN for CartPole using a Boltzmann Q policy for selecting the actions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGsC7cJ5jNcX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda73cbf-3020-40f4-e45e-7b87053448f1"
      },
      "source": [
        "# install keras rl2 (we need to install keras-rl2 so it works with the tensorflow 2 version that comes pre-installed with colab)\n",
        "!pip install keras-rl2"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-rl2 in /usr/local/lib/python3.7/dist-packages (1.0.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras-rl2) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.24.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (13.0.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.5.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.44.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.14.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.0.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.15.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.21.5)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.10.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (57.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->keras-rl2) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->keras-rl2) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMIHLgQ3Z-lF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d5a8608-456f-4127-ce8a-f551e5f4e4f3"
      },
      "source": [
        "!pip install gym"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0AMLzq08ap0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77b380e1-6c3d-4bce-8233-a8ac01deaf26"
      },
      "source": [
        "# load the gym module\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "# import the usual Keras modules for creating deep neural networks\n",
        "from keras import Sequential\n",
        "from keras.layers import Input, Flatten, Dense\n",
        "!pip install Adam\n",
        "#from keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "ENV_NAME = 'CartPole-v0'\n",
        "env = gym.make(ENV_NAME)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Adam in /usr/local/lib/python3.7/dist-packages (0.0.0.dev0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll6bNdUm54WS"
      },
      "source": [
        "Implementation of DQN for CartPole, applying policy BoltzmannQPolicy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSCrPKNy40PC"
      },
      "source": [
        "##Implement DQN with BoltzmannGumbelQPolicy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efM9jkXr5A3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "223d846c-15e5-4b0a-8ec6-04bc7ac3ca77"
      },
      "source": [
        "import rl\n",
        "from rl.memory import SequentialMemory  # import the exerience replay buffer module\n",
        "from rl.policy import BoltzmannGumbelQPolicy\n",
        "from rl.policy import LinearAnnealedPolicy\n",
        "from rl.policy import EpsGreedyQPolicy\n",
        "from rl.agents.dqn import DQNAgent      # import the DQN agent\n",
        "\n",
        "# setup experience replay buffer\n",
        "memory = SequentialMemory(limit=10000, window_length=1)\n",
        "\n",
        "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), \n",
        "                               attr='eps',            \n",
        "                               value_max=5.,\n",
        "                               value_min=.5, \n",
        "                               value_test=.05,\n",
        "                               nb_steps=20)\n",
        "# Q-Network\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(1,env.observation_space.shape[0])))  # The input is 1 observation vector, and the number of observations in that vector \n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "# add extra layers here\n",
        "model.add(Dense(env.action_space.n, activation='linear'))   # the output is the number of actions in the action space\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# define the agent\n",
        "dqn = DQNAgent(model=model, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=20,\n",
        "               target_model_update=1e-2, \n",
        "               policy=policy) \n",
        "\n",
        "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
        "\n",
        "history = dqn.fit(env, nb_steps=8000, visualize=False, verbose=2)\n",
        "\n",
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()\n",
        "\n",
        "dqn.test(env, nb_episodes=20, visualize=False)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_50\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_48 (Flatten)        (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 32)                160       \n",
            "                                                                 \n",
            " dense_98 (Dense)            (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 226\n",
            "Trainable params: 226\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 8000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "/usr/local/lib/python3.7/dist-packages/rl/memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
            "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   36/8000: episode: 1, duration: 15.624s, episode steps:  36, steps per second:   2, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 0.512353, mae: 0.563789, mean_q: 0.010869, mean_eps: 0.500000\n",
            "   57/8000: episode: 2, duration: 0.557s, episode steps:  21, steps per second:  38, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.762 [0.000, 1.000],  loss: 0.421546, mae: 0.536328, mean_q: 0.195778, mean_eps: 0.500000\n",
            "   74/8000: episode: 3, duration: 0.451s, episode steps:  17, steps per second:  38, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.824 [0.000, 1.000],  loss: 0.300877, mae: 0.467727, mean_q: 0.435411, mean_eps: 0.500000\n",
            "   88/8000: episode: 4, duration: 0.433s, episode steps:  14, steps per second:  32, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 0.254742, mae: 0.439825, mean_q: 0.599421, mean_eps: 0.500000\n",
            "   98/8000: episode: 5, duration: 0.311s, episode steps:  10, steps per second:  32, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.100 [0.000, 1.000],  loss: 0.235827, mae: 0.457246, mean_q: 0.723501, mean_eps: 0.500000\n",
            "  118/8000: episode: 6, duration: 0.533s, episode steps:  20, steps per second:  38, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 0.212929, mae: 0.515914, mean_q: 0.761645, mean_eps: 0.500000\n",
            "  132/8000: episode: 7, duration: 0.394s, episode steps:  14, steps per second:  36, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.214 [0.000, 1.000],  loss: 0.188664, mae: 0.582080, mean_q: 0.923429, mean_eps: 0.500000\n",
            "  142/8000: episode: 8, duration: 0.304s, episode steps:  10, steps per second:  33, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 0.166801, mae: 0.618960, mean_q: 1.005973, mean_eps: 0.500000\n",
            "  158/8000: episode: 9, duration: 0.438s, episode steps:  16, steps per second:  37, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 0.146163, mae: 0.648153, mean_q: 1.076938, mean_eps: 0.500000\n",
            "  168/8000: episode: 10, duration: 0.235s, episode steps:  10, steps per second:  43, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.900 [0.000, 1.000],  loss: 0.160606, mae: 0.730848, mean_q: 1.226935, mean_eps: 0.500000\n",
            "  178/8000: episode: 11, duration: 0.181s, episode steps:  10, steps per second:  55, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 0.132777, mae: 0.747205, mean_q: 1.277130, mean_eps: 0.500000\n",
            "  194/8000: episode: 12, duration: 0.308s, episode steps:  16, steps per second:  52, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 0.132408, mae: 0.808229, mean_q: 1.417137, mean_eps: 0.500000\n",
            "  205/8000: episode: 13, duration: 0.195s, episode steps:  11, steps per second:  57, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.818 [0.000, 1.000],  loss: 0.116456, mae: 0.836994, mean_q: 1.477783, mean_eps: 0.500000\n",
            "  215/8000: episode: 14, duration: 0.170s, episode steps:  10, steps per second:  59, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 0.140020, mae: 0.902323, mean_q: 1.613092, mean_eps: 0.500000\n",
            "  226/8000: episode: 15, duration: 0.271s, episode steps:  11, steps per second:  41, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.182 [0.000, 1.000],  loss: 0.143825, mae: 0.948774, mean_q: 1.723406, mean_eps: 0.500000\n",
            "  239/8000: episode: 16, duration: 0.311s, episode steps:  13, steps per second:  42, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.154 [0.000, 1.000],  loss: 0.147032, mae: 0.980983, mean_q: 1.782398, mean_eps: 0.500000\n",
            "  255/8000: episode: 17, duration: 0.447s, episode steps:  16, steps per second:  36, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.250 [0.000, 1.000],  loss: 0.172643, mae: 1.065245, mean_q: 1.886838, mean_eps: 0.500000\n",
            "  266/8000: episode: 18, duration: 0.224s, episode steps:  11, steps per second:  49, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.909 [0.000, 1.000],  loss: 0.156153, mae: 1.084993, mean_q: 1.944214, mean_eps: 0.500000\n",
            "  276/8000: episode: 19, duration: 0.154s, episode steps:  10, steps per second:  65, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 0.126260, mae: 1.098135, mean_q: 2.099155, mean_eps: 0.500000\n",
            "  292/8000: episode: 20, duration: 0.255s, episode steps:  16, steps per second:  63, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.750 [0.000, 1.000],  loss: 0.164970, mae: 1.153024, mean_q: 2.222950, mean_eps: 0.500000\n",
            "  304/8000: episode: 21, duration: 0.234s, episode steps:  12, steps per second:  51, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.833 [0.000, 1.000],  loss: 0.188856, mae: 1.212607, mean_q: 2.315315, mean_eps: 0.500000\n",
            "  317/8000: episode: 22, duration: 0.232s, episode steps:  13, steps per second:  56, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 0.175684, mae: 1.246581, mean_q: 2.364147, mean_eps: 0.500000\n",
            "  333/8000: episode: 23, duration: 0.254s, episode steps:  16, steps per second:  63, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.250 [0.000, 1.000],  loss: 0.182960, mae: 1.333365, mean_q: 2.524429, mean_eps: 0.500000\n",
            "  350/8000: episode: 24, duration: 0.274s, episode steps:  17, steps per second:  62, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.765 [0.000, 1.000],  loss: 0.193130, mae: 1.393771, mean_q: 2.601846, mean_eps: 0.500000\n",
            "  361/8000: episode: 25, duration: 0.189s, episode steps:  11, steps per second:  58, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.727 [0.000, 1.000],  loss: 0.160592, mae: 1.440914, mean_q: 2.693935, mean_eps: 0.500000\n",
            "  372/8000: episode: 26, duration: 0.187s, episode steps:  11, steps per second:  59, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.091 [0.000, 1.000],  loss: 0.183446, mae: 1.491667, mean_q: 2.804825, mean_eps: 0.500000\n",
            "  390/8000: episode: 27, duration: 0.277s, episode steps:  18, steps per second:  65, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.333 [0.000, 1.000],  loss: 0.156086, mae: 1.534509, mean_q: 2.909928, mean_eps: 0.500000\n",
            "  401/8000: episode: 28, duration: 0.197s, episode steps:  11, steps per second:  56, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 0.237439, mae: 1.646305, mean_q: 3.033258, mean_eps: 0.500000\n",
            "  413/8000: episode: 29, duration: 0.239s, episode steps:  12, steps per second:  50, episode reward: 12.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.583 [0.000, 1.000],  loss: 0.132138, mae: 1.624440, mean_q: 3.031001, mean_eps: 0.500000\n",
            "  423/8000: episode: 30, duration: 0.221s, episode steps:  10, steps per second:  45, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.800 [0.000, 1.000],  loss: 0.185980, mae: 1.682806, mean_q: 3.169931, mean_eps: 0.500000\n",
            "  431/8000: episode: 31, duration: 0.168s, episode steps:   8, steps per second:  48, episode reward:  8.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 0.183653, mae: 1.737027, mean_q: 3.260393, mean_eps: 0.500000\n",
            "  444/8000: episode: 32, duration: 0.240s, episode steps:  13, steps per second:  54, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 0.220882, mae: 1.790539, mean_q: 3.320312, mean_eps: 0.500000\n",
            "  457/8000: episode: 33, duration: 0.245s, episode steps:  13, steps per second:  53, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.769 [0.000, 1.000],  loss: 0.198118, mae: 1.829518, mean_q: 3.392357, mean_eps: 0.500000\n",
            "  467/8000: episode: 34, duration: 0.195s, episode steps:  10, steps per second:  51, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.900 [0.000, 1.000],  loss: 0.229681, mae: 1.876466, mean_q: 3.503192, mean_eps: 0.500000\n",
            "  477/8000: episode: 35, duration: 0.190s, episode steps:  10, steps per second:  53, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.200 [0.000, 1.000],  loss: 0.227316, mae: 1.920893, mean_q: 3.593856, mean_eps: 0.500000\n",
            "  487/8000: episode: 36, duration: 0.197s, episode steps:  10, steps per second:  51, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 0.261256, mae: 1.953055, mean_q: 3.659882, mean_eps: 0.500000\n",
            "  500/8000: episode: 37, duration: 0.216s, episode steps:  13, steps per second:  60, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.769 [0.000, 1.000],  loss: 0.270786, mae: 1.993860, mean_q: 3.703502, mean_eps: 0.500000\n",
            "  511/8000: episode: 38, duration: 0.178s, episode steps:  11, steps per second:  62, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.818 [0.000, 1.000],  loss: 0.280458, mae: 2.016952, mean_q: 3.750171, mean_eps: 0.500000\n",
            "  527/8000: episode: 39, duration: 0.270s, episode steps:  16, steps per second:  59, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 0.288293, mae: 2.072409, mean_q: 3.842913, mean_eps: 0.500000\n",
            "  535/8000: episode: 40, duration: 0.135s, episode steps:   8, steps per second:  59, episode reward:  8.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 0.359186, mae: 2.143036, mean_q: 3.915558, mean_eps: 0.500000\n",
            "  543/8000: episode: 41, duration: 0.136s, episode steps:   8, steps per second:  59, episode reward:  8.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 1.000 [1.000, 1.000],  loss: 0.384701, mae: 2.168748, mean_q: 3.897306, mean_eps: 0.500000\n",
            "  584/8000: episode: 42, duration: 0.943s, episode steps:  41, steps per second:  43, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.561 [0.000, 1.000],  loss: 0.297271, mae: 2.232959, mean_q: 4.133738, mean_eps: 0.500000\n",
            "  594/8000: episode: 43, duration: 0.284s, episode steps:  10, steps per second:  35, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.900 [0.000, 1.000],  loss: 0.389697, mae: 2.348185, mean_q: 4.318681, mean_eps: 0.500000\n",
            "  623/8000: episode: 44, duration: 0.773s, episode steps:  29, steps per second:  38, episode reward: 29.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.310 [0.000, 1.000],  loss: 0.346747, mae: 2.372755, mean_q: 4.351078, mean_eps: 0.500000\n",
            "  633/8000: episode: 45, duration: 0.274s, episode steps:  10, steps per second:  36, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 0.341216, mae: 2.421687, mean_q: 4.511131, mean_eps: 0.500000\n",
            "  665/8000: episode: 46, duration: 0.836s, episode steps:  32, steps per second:  38, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.312 [0.000, 1.000],  loss: 0.294110, mae: 2.488406, mean_q: 4.642949, mean_eps: 0.500000\n",
            "  676/8000: episode: 47, duration: 0.316s, episode steps:  11, steps per second:  35, episode reward: 11.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.364 [0.000, 1.000],  loss: 0.326991, mae: 2.576690, mean_q: 4.866068, mean_eps: 0.500000\n",
            "  693/8000: episode: 48, duration: 0.421s, episode steps:  17, steps per second:  40, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 0.328452, mae: 2.584634, mean_q: 4.859442, mean_eps: 0.500000\n",
            "  717/8000: episode: 49, duration: 0.639s, episode steps:  24, steps per second:  38, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.292 [0.000, 1.000],  loss: 0.441223, mae: 2.664613, mean_q: 4.975726, mean_eps: 0.500000\n",
            "  727/8000: episode: 50, duration: 0.304s, episode steps:  10, steps per second:  33, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.800 [0.000, 1.000],  loss: 0.286330, mae: 2.628137, mean_q: 5.016157, mean_eps: 0.500000\n",
            "  736/8000: episode: 51, duration: 0.273s, episode steps:   9, steps per second:  33, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.000 [0.000, 0.000],  loss: 0.327740, mae: 2.680555, mean_q: 5.163410, mean_eps: 0.500000\n",
            "  776/8000: episode: 52, duration: 1.079s, episode steps:  40, steps per second:  37, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.350 [0.000, 1.000],  loss: 0.417762, mae: 2.827951, mean_q: 5.295335, mean_eps: 0.500000\n",
            "  830/8000: episode: 53, duration: 1.214s, episode steps:  54, steps per second:  44, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.407 [0.000, 1.000],  loss: 0.401279, mae: 2.971324, mean_q: 5.607430, mean_eps: 0.500000\n",
            "  871/8000: episode: 54, duration: 1.075s, episode steps:  41, steps per second:  38, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.537 [0.000, 1.000],  loss: 0.432831, mae: 3.110600, mean_q: 5.873306, mean_eps: 0.500000\n",
            "  886/8000: episode: 55, duration: 0.318s, episode steps:  15, steps per second:  47, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.467 [0.000, 1.000],  loss: 0.389293, mae: 3.231902, mean_q: 6.157440, mean_eps: 0.500000\n",
            "  943/8000: episode: 56, duration: 1.070s, episode steps:  57, steps per second:  53, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.509 [0.000, 1.000],  loss: 0.466283, mae: 3.330534, mean_q: 6.347732, mean_eps: 0.500000\n",
            "  981/8000: episode: 57, duration: 0.731s, episode steps:  38, steps per second:  52, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.568448, mae: 3.540009, mean_q: 6.700041, mean_eps: 0.500000\n",
            " 1017/8000: episode: 58, duration: 0.730s, episode steps:  36, steps per second:  49, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.417 [0.000, 1.000],  loss: 0.497913, mae: 3.652622, mean_q: 6.998261, mean_eps: 0.500000\n",
            " 1041/8000: episode: 59, duration: 0.571s, episode steps:  24, steps per second:  42, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.375 [0.000, 1.000],  loss: 0.524077, mae: 3.735991, mean_q: 7.122598, mean_eps: 0.500000\n",
            " 1086/8000: episode: 60, duration: 1.257s, episode steps:  45, steps per second:  36, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.422 [0.000, 1.000],  loss: 0.632388, mae: 3.853071, mean_q: 7.298637, mean_eps: 0.500000\n",
            " 1226/8000: episode: 61, duration: 3.763s, episode steps: 140, steps per second:  37, episode reward: 140.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 0.704335, mae: 4.184320, mean_q: 7.966492, mean_eps: 0.500000\n",
            " 1243/8000: episode: 62, duration: 0.362s, episode steps:  17, steps per second:  47, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 0.756078, mae: 4.483693, mean_q: 8.581107, mean_eps: 0.500000\n",
            " 1366/8000: episode: 63, duration: 2.902s, episode steps: 123, steps per second:  42, episode reward: 123.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.480 [0.000, 1.000],  loss: 0.834689, mae: 4.712287, mean_q: 9.018101, mean_eps: 0.500000\n",
            " 1447/8000: episode: 64, duration: 2.019s, episode steps:  81, steps per second:  40, episode reward: 81.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.494 [0.000, 1.000],  loss: 0.873906, mae: 5.009883, mean_q: 9.613280, mean_eps: 0.500000\n",
            " 1513/8000: episode: 65, duration: 1.374s, episode steps:  66, steps per second:  48, episode reward: 66.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.470 [0.000, 1.000],  loss: 1.202034, mae: 5.285281, mean_q: 10.120488, mean_eps: 0.500000\n",
            " 1608/8000: episode: 66, duration: 2.023s, episode steps:  95, steps per second:  47, episode reward: 95.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 1.192699, mae: 5.538127, mean_q: 10.590859, mean_eps: 0.500000\n",
            " 1671/8000: episode: 67, duration: 1.615s, episode steps:  63, steps per second:  39, episode reward: 63.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.460 [0.000, 1.000],  loss: 1.158654, mae: 5.693579, mean_q: 10.877875, mean_eps: 0.500000\n",
            " 1756/8000: episode: 68, duration: 1.683s, episode steps:  85, steps per second:  51, episode reward: 85.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.494 [0.000, 1.000],  loss: 1.118488, mae: 5.943502, mean_q: 11.468010, mean_eps: 0.500000\n",
            " 1806/8000: episode: 69, duration: 0.930s, episode steps:  50, steps per second:  54, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.244287, mae: 6.165824, mean_q: 11.902809, mean_eps: 0.500000\n",
            " 1853/8000: episode: 70, duration: 0.831s, episode steps:  47, steps per second:  57, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 1.469761, mae: 6.327975, mean_q: 12.177592, mean_eps: 0.500000\n",
            " 1901/8000: episode: 71, duration: 1.295s, episode steps:  48, steps per second:  37, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 1.253167, mae: 6.504590, mean_q: 12.611472, mean_eps: 0.500000\n",
            " 1997/8000: episode: 72, duration: 2.449s, episode steps:  96, steps per second:  39, episode reward: 96.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.554984, mae: 6.771868, mean_q: 13.113325, mean_eps: 0.500000\n",
            " 2088/8000: episode: 73, duration: 2.382s, episode steps:  91, steps per second:  38, episode reward: 91.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 1.347754, mae: 7.070073, mean_q: 13.751207, mean_eps: 0.500000\n",
            " 2121/8000: episode: 74, duration: 0.817s, episode steps:  33, steps per second:  40, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 1.985484, mae: 7.316046, mean_q: 14.143882, mean_eps: 0.500000\n",
            " 2159/8000: episode: 75, duration: 0.976s, episode steps:  38, steps per second:  39, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 1.415923, mae: 7.407167, mean_q: 14.402708, mean_eps: 0.500000\n",
            " 2206/8000: episode: 76, duration: 1.240s, episode steps:  47, steps per second:  38, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 1.742701, mae: 7.527796, mean_q: 14.625253, mean_eps: 0.500000\n",
            " 2251/8000: episode: 77, duration: 1.073s, episode steps:  45, steps per second:  42, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.489 [0.000, 1.000],  loss: 1.546625, mae: 7.653412, mean_q: 14.874831, mean_eps: 0.500000\n",
            " 2270/8000: episode: 78, duration: 0.433s, episode steps:  19, steps per second:  44, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.474 [0.000, 1.000],  loss: 2.258348, mae: 7.790592, mean_q: 15.107042, mean_eps: 0.500000\n",
            " 2322/8000: episode: 79, duration: 1.145s, episode steps:  52, steps per second:  45, episode reward: 52.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.462 [0.000, 1.000],  loss: 1.682449, mae: 7.866866, mean_q: 15.256866, mean_eps: 0.500000\n",
            " 2396/8000: episode: 80, duration: 1.821s, episode steps:  74, steps per second:  41, episode reward: 74.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.031327, mae: 8.045594, mean_q: 15.610546, mean_eps: 0.500000\n",
            " 2424/8000: episode: 81, duration: 0.721s, episode steps:  28, steps per second:  39, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 2.204006, mae: 8.166327, mean_q: 15.824027, mean_eps: 0.500000\n",
            " 2496/8000: episode: 82, duration: 1.850s, episode steps:  72, steps per second:  39, episode reward: 72.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 1.958823, mae: 8.339671, mean_q: 16.233243, mean_eps: 0.500000\n",
            " 2529/8000: episode: 83, duration: 0.891s, episode steps:  33, steps per second:  37, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 2.422344, mae: 8.493283, mean_q: 16.490860, mean_eps: 0.500000\n",
            " 2602/8000: episode: 84, duration: 1.755s, episode steps:  73, steps per second:  42, episode reward: 73.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.507 [0.000, 1.000],  loss: 2.285153, mae: 8.670747, mean_q: 16.814923, mean_eps: 0.500000\n",
            " 2634/8000: episode: 85, duration: 0.563s, episode steps:  32, steps per second:  57, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 2.204064, mae: 8.850451, mean_q: 17.272022, mean_eps: 0.500000\n",
            " 2657/8000: episode: 86, duration: 0.470s, episode steps:  23, steps per second:  49, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.478 [0.000, 1.000],  loss: 1.900895, mae: 8.848343, mean_q: 17.236054, mean_eps: 0.500000\n",
            " 2697/8000: episode: 87, duration: 0.998s, episode steps:  40, steps per second:  40, episode reward: 40.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 2.484552, mae: 9.038514, mean_q: 17.603811, mean_eps: 0.500000\n",
            " 2739/8000: episode: 88, duration: 1.005s, episode steps:  42, steps per second:  42, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 2.931847, mae: 9.159727, mean_q: 17.729168, mean_eps: 0.500000\n",
            " 2787/8000: episode: 89, duration: 1.207s, episode steps:  48, steps per second:  40, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.542 [0.000, 1.000],  loss: 3.128049, mae: 9.285803, mean_q: 18.019724, mean_eps: 0.500000\n",
            " 2914/8000: episode: 90, duration: 2.193s, episode steps: 127, steps per second:  58, episode reward: 127.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.504 [0.000, 1.000],  loss: 2.964002, mae: 9.539032, mean_q: 18.539543, mean_eps: 0.500000\n",
            " 2934/8000: episode: 91, duration: 0.344s, episode steps:  20, steps per second:  58, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.400 [0.000, 1.000],  loss: 3.645136, mae: 9.752436, mean_q: 18.957703, mean_eps: 0.500000\n",
            " 3065/8000: episode: 92, duration: 2.000s, episode steps: 131, steps per second:  66, episode reward: 131.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 2.598317, mae: 9.932781, mean_q: 19.410123, mean_eps: 0.500000\n",
            " 3127/8000: episode: 93, duration: 1.464s, episode steps:  62, steps per second:  42, episode reward: 62.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.468 [0.000, 1.000],  loss: 2.493882, mae: 10.282332, mean_q: 20.178671, mean_eps: 0.500000\n",
            " 3163/8000: episode: 94, duration: 0.897s, episode steps:  36, steps per second:  40, episode reward: 36.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 3.446200, mae: 10.414180, mean_q: 20.249643, mean_eps: 0.500000\n",
            " 3218/8000: episode: 95, duration: 1.207s, episode steps:  55, steps per second:  46, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 3.536724, mae: 10.516730, mean_q: 20.503899, mean_eps: 0.500000\n",
            " 3299/8000: episode: 96, duration: 1.245s, episode steps:  81, steps per second:  65, episode reward: 81.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.469 [0.000, 1.000],  loss: 3.426586, mae: 10.672594, mean_q: 20.781995, mean_eps: 0.500000\n",
            " 3416/8000: episode: 97, duration: 2.098s, episode steps: 117, steps per second:  56, episode reward: 117.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.521 [0.000, 1.000],  loss: 3.038903, mae: 10.875659, mean_q: 21.262653, mean_eps: 0.500000\n",
            " 3473/8000: episode: 98, duration: 1.345s, episode steps:  57, steps per second:  42, episode reward: 57.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.491 [0.000, 1.000],  loss: 3.039640, mae: 11.157672, mean_q: 21.896831, mean_eps: 0.500000\n",
            " 3673/8000: episode: 99, duration: 4.072s, episode steps: 200, steps per second:  49, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 3.432478, mae: 11.528364, mean_q: 22.632818, mean_eps: 0.500000\n",
            " 3724/8000: episode: 100, duration: 1.245s, episode steps:  51, steps per second:  41, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 3.522703, mae: 11.854524, mean_q: 23.193637, mean_eps: 0.500000\n",
            " 3848/8000: episode: 101, duration: 2.298s, episode steps: 124, steps per second:  54, episode reward: 124.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 4.455063, mae: 12.072341, mean_q: 23.596115, mean_eps: 0.500000\n",
            " 3869/8000: episode: 102, duration: 0.347s, episode steps:  21, steps per second:  60, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.619 [0.000, 1.000],  loss: 4.530640, mae: 12.225633, mean_q: 23.928536, mean_eps: 0.500000\n",
            " 4018/8000: episode: 103, duration: 3.200s, episode steps: 149, steps per second:  47, episode reward: 149.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 3.732557, mae: 12.460261, mean_q: 24.475312, mean_eps: 0.500000\n",
            " 4065/8000: episode: 104, duration: 1.235s, episode steps:  47, steps per second:  38, episode reward: 47.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.447 [0.000, 1.000],  loss: 3.133548, mae: 12.696470, mean_q: 25.070320, mean_eps: 0.500000\n",
            " 4154/8000: episode: 105, duration: 1.711s, episode steps:  89, steps per second:  52, episode reward: 89.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 4.855386, mae: 12.907426, mean_q: 25.302825, mean_eps: 0.500000\n",
            " 4208/8000: episode: 106, duration: 1.387s, episode steps:  54, steps per second:  39, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.519 [0.000, 1.000],  loss: 4.334436, mae: 13.082152, mean_q: 25.812950, mean_eps: 0.500000\n",
            " 4267/8000: episode: 107, duration: 1.101s, episode steps:  59, steps per second:  54, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 4.841801, mae: 13.210473, mean_q: 25.990783, mean_eps: 0.500000\n",
            " 4312/8000: episode: 108, duration: 1.056s, episode steps:  45, steps per second:  43, episode reward: 45.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 4.225463, mae: 13.292452, mean_q: 26.227521, mean_eps: 0.500000\n",
            " 4384/8000: episode: 109, duration: 1.338s, episode steps:  72, steps per second:  54, episode reward: 72.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.569 [0.000, 1.000],  loss: 5.440655, mae: 13.502710, mean_q: 26.453145, mean_eps: 0.500000\n",
            " 4483/8000: episode: 110, duration: 2.572s, episode steps:  99, steps per second:  38, episode reward: 99.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.535 [0.000, 1.000],  loss: 4.399441, mae: 13.678882, mean_q: 26.882266, mean_eps: 0.500000\n",
            " 4551/8000: episode: 111, duration: 1.634s, episode steps:  68, steps per second:  42, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 2.977159, mae: 13.916970, mean_q: 27.542397, mean_eps: 0.500000\n",
            " 4607/8000: episode: 112, duration: 1.443s, episode steps:  56, steps per second:  39, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 3.969517, mae: 14.151212, mean_q: 27.943788, mean_eps: 0.500000\n",
            " 4640/8000: episode: 113, duration: 0.564s, episode steps:  33, steps per second:  58, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 3.577214, mae: 14.267169, mean_q: 28.189167, mean_eps: 0.500000\n",
            " 4759/8000: episode: 114, duration: 2.455s, episode steps: 119, steps per second:  48, episode reward: 119.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.521 [0.000, 1.000],  loss: 4.668715, mae: 14.362227, mean_q: 28.260194, mean_eps: 0.500000\n",
            " 4777/8000: episode: 115, duration: 0.508s, episode steps:  18, steps per second:  35, episode reward: 18.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.444 [0.000, 1.000],  loss: 8.013039, mae: 14.546935, mean_q: 28.343975, mean_eps: 0.500000\n",
            " 4802/8000: episode: 116, duration: 0.618s, episode steps:  25, steps per second:  40, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.440 [0.000, 1.000],  loss: 5.404505, mae: 14.490617, mean_q: 28.391643, mean_eps: 0.500000\n",
            " 4863/8000: episode: 117, duration: 1.063s, episode steps:  61, steps per second:  57, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.459 [0.000, 1.000],  loss: 4.125333, mae: 14.636310, mean_q: 28.857064, mean_eps: 0.500000\n",
            " 5003/8000: episode: 118, duration: 2.283s, episode steps: 140, steps per second:  61, episode reward: 140.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 4.588694, mae: 14.860330, mean_q: 29.286955, mean_eps: 0.500000\n",
            " 5023/8000: episode: 119, duration: 0.346s, episode steps:  20, steps per second:  58, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.450 [0.000, 1.000],  loss: 4.821206, mae: 15.002500, mean_q: 29.562434, mean_eps: 0.500000\n",
            " 5112/8000: episode: 120, duration: 2.134s, episode steps:  89, steps per second:  42, episode reward: 89.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.472 [0.000, 1.000],  loss: 4.956670, mae: 15.187059, mean_q: 29.953162, mean_eps: 0.500000\n",
            " 5217/8000: episode: 121, duration: 2.729s, episode steps: 105, steps per second:  38, episode reward: 105.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.543 [0.000, 1.000],  loss: 4.487038, mae: 15.367592, mean_q: 30.388986, mean_eps: 0.500000\n",
            " 5297/8000: episode: 122, duration: 1.490s, episode steps:  80, steps per second:  54, episode reward: 80.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 5.520524, mae: 15.655515, mean_q: 30.920186, mean_eps: 0.500000\n",
            " 5406/8000: episode: 123, duration: 2.150s, episode steps: 109, steps per second:  51, episode reward: 109.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.459 [0.000, 1.000],  loss: 4.791726, mae: 15.784236, mean_q: 31.288766, mean_eps: 0.500000\n",
            " 5437/8000: episode: 124, duration: 0.820s, episode steps:  31, steps per second:  38, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.516 [0.000, 1.000],  loss: 5.901931, mae: 15.999071, mean_q: 31.563316, mean_eps: 0.500000\n",
            " 5509/8000: episode: 125, duration: 1.932s, episode steps:  72, steps per second:  37, episode reward: 72.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 6.886465, mae: 16.093286, mean_q: 31.634813, mean_eps: 0.500000\n",
            " 5651/8000: episode: 126, duration: 2.483s, episode steps: 142, steps per second:  57, episode reward: 142.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.535 [0.000, 1.000],  loss: 5.451223, mae: 16.381130, mean_q: 32.389339, mean_eps: 0.500000\n",
            " 5670/8000: episode: 127, duration: 0.345s, episode steps:  19, steps per second:  55, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.579 [0.000, 1.000],  loss: 4.319707, mae: 16.449811, mean_q: 32.561289, mean_eps: 0.500000\n",
            " 5793/8000: episode: 128, duration: 2.378s, episode steps: 123, steps per second:  52, episode reward: 123.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 7.110434, mae: 16.637396, mean_q: 32.788469, mean_eps: 0.500000\n",
            " 5970/8000: episode: 129, duration: 3.822s, episode steps: 177, steps per second:  46, episode reward: 177.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.492 [0.000, 1.000],  loss: 4.833606, mae: 16.922485, mean_q: 33.682252, mean_eps: 0.500000\n",
            " 6154/8000: episode: 130, duration: 4.358s, episode steps: 184, steps per second:  42, episode reward: 184.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 6.476668, mae: 17.428089, mean_q: 34.636445, mean_eps: 0.500000\n",
            " 6354/8000: episode: 131, duration: 4.097s, episode steps: 200, steps per second:  49, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 6.464653, mae: 17.787303, mean_q: 35.309563, mean_eps: 0.500000\n",
            " 6400/8000: episode: 132, duration: 0.877s, episode steps:  46, steps per second:  52, episode reward: 46.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 5.508706, mae: 18.114841, mean_q: 36.047608, mean_eps: 0.500000\n",
            " 6472/8000: episode: 133, duration: 1.535s, episode steps:  72, steps per second:  47, episode reward: 72.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.514 [0.000, 1.000],  loss: 7.649980, mae: 18.216357, mean_q: 36.072765, mean_eps: 0.500000\n",
            " 6550/8000: episode: 134, duration: 1.270s, episode steps:  78, steps per second:  61, episode reward: 78.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 6.882124, mae: 18.359887, mean_q: 36.440324, mean_eps: 0.500000\n",
            " 6578/8000: episode: 135, duration: 0.502s, episode steps:  28, steps per second:  56, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 6.688318, mae: 18.476365, mean_q: 36.717574, mean_eps: 0.500000\n",
            " 6704/8000: episode: 136, duration: 2.455s, episode steps: 126, steps per second:  51, episode reward: 126.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.452 [0.000, 1.000],  loss: 6.939496, mae: 18.598428, mean_q: 36.880801, mean_eps: 0.500000\n",
            " 6752/8000: episode: 137, duration: 1.065s, episode steps:  48, steps per second:  45, episode reward: 48.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 6.621594, mae: 18.594604, mean_q: 37.022852, mean_eps: 0.500000\n",
            " 6847/8000: episode: 138, duration: 1.550s, episode steps:  95, steps per second:  61, episode reward: 95.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.495 [0.000, 1.000],  loss: 7.679058, mae: 18.839737, mean_q: 37.424068, mean_eps: 0.500000\n",
            " 6882/8000: episode: 139, duration: 0.648s, episode steps:  35, steps per second:  54, episode reward: 35.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 6.685949, mae: 19.105222, mean_q: 38.087201, mean_eps: 0.500000\n",
            " 7059/8000: episode: 140, duration: 3.372s, episode steps: 177, steps per second:  52, episode reward: 177.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 7.079357, mae: 19.270112, mean_q: 38.371588, mean_eps: 0.500000\n",
            " 7149/8000: episode: 141, duration: 2.524s, episode steps:  90, steps per second:  36, episode reward: 90.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 5.486575, mae: 19.555589, mean_q: 39.092401, mean_eps: 0.500000\n",
            " 7349/8000: episode: 142, duration: 4.339s, episode steps: 200, steps per second:  46, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 7.304674, mae: 19.946264, mean_q: 39.756320, mean_eps: 0.500000\n",
            " 7434/8000: episode: 143, duration: 1.650s, episode steps:  85, steps per second:  52, episode reward: 85.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.518 [0.000, 1.000],  loss: 7.818983, mae: 20.323243, mean_q: 40.478971, mean_eps: 0.500000\n",
            " 7592/8000: episode: 144, duration: 2.788s, episode steps: 158, steps per second:  57, episode reward: 158.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.506 [0.000, 1.000],  loss: 7.129157, mae: 20.514579, mean_q: 40.910175, mean_eps: 0.500000\n",
            " 7686/8000: episode: 145, duration: 2.173s, episode steps:  94, steps per second:  43, episode reward: 94.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.511 [0.000, 1.000],  loss: 7.325647, mae: 20.782069, mean_q: 41.581568, mean_eps: 0.500000\n",
            " 7848/8000: episode: 146, duration: 2.810s, episode steps: 162, steps per second:  58, episode reward: 162.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.481 [0.000, 1.000],  loss: 7.544573, mae: 21.154889, mean_q: 42.258800, mean_eps: 0.500000\n",
            "done, took 186.574 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb16fb7f190>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    }
  ]
}