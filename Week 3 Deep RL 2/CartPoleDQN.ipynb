{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CartPoleDQN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Megacity1/CartpoleDQN/blob/main/Week%203%20Deep%20RL%202/CartPoleDQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKK5DA390wRe"
      },
      "source": [
        "# Deep Q Network (DQN) for CartPole Using Boltzmann Q Policy\n",
        "This exercise implements a DQN for CartPole using a Boltzmann Q policy for selecting the actions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGsC7cJ5jNcX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda73cbf-3020-40f4-e45e-7b87053448f1"
      },
      "source": [
        "# install keras rl2 (we need to install keras-rl2 so it works with the tensorflow 2 version that comes pre-installed with colab)\n",
        "!pip install keras-rl2"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-rl2 in /usr/local/lib/python3.7/dist-packages (1.0.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras-rl2) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.24.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (13.0.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.5.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.44.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.14.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.0.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.15.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.21.5)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.10.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (57.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->keras-rl2) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->keras-rl2) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras-rl2) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMIHLgQ3Z-lF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d5a8608-456f-4127-ce8a-f551e5f4e4f3"
      },
      "source": [
        "!pip install gym"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0AMLzq08ap0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77b380e1-6c3d-4bce-8233-a8ac01deaf26"
      },
      "source": [
        "# load the gym module\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "# import the usual Keras modules for creating deep neural networks\n",
        "from keras import Sequential\n",
        "from keras.layers import Input, Flatten, Dense\n",
        "!pip install Adam\n",
        "#from keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "ENV_NAME = 'CartPole-v0'\n",
        "env = gym.make(ENV_NAME)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Adam in /usr/local/lib/python3.7/dist-packages (0.0.0.dev0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll6bNdUm54WS"
      },
      "source": [
        "Implementation of DQN for CartPole, applying policy BoltzmannQPolicy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSCrPKNy40PC"
      },
      "source": [
        "##Implement DQN with BoltzmannGumbelQPolicy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efM9jkXr5A3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c18111bd-aa64-4439-c5c4-048d83225ff2"
      },
      "source": [
        "import rl\n",
        "from rl.memory import SequentialMemory  # import the exerience replay buffer module\n",
        "from rl.policy import BoltzmannGumbelQPolicy\n",
        "from rl.policy import LinearAnnealedPolicy\n",
        "from rl.policy import EpsGreedyQPolicy\n",
        "from rl.agents.dqn import DQNAgent      # import the DQN agent\n",
        "\n",
        "# setup experience replay buffer\n",
        "memory = SequentialMemory(limit=10000, window_length=1)\n",
        "\n",
        "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), \n",
        "                               attr='eps',            \n",
        "                               value_max=5.,\n",
        "                               value_min=.10, \n",
        "                               value_test=.05,\n",
        "                               nb_steps=20)\n",
        "# Q-Network\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(1,env.observation_space.shape[0])))  # The input is 1 observation vector, and the number of observations in that vector \n",
        "model.add(Flatten())\n",
        "model.add(Dense(16, activation='relu'))\n",
        "# add extra layers here\n",
        "model.add(Dense(env.action_space.n, activation='linear'))   # the output is the number of actions in the action space\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# define the agent\n",
        "dqn = DQNAgent(model=model, \n",
        "               nb_actions=env.action_space.n,\n",
        "               memory=memory,\n",
        "               nb_steps_warmup=20,\n",
        "               target_model_update=1e-2, \n",
        "               policy=policy) \n",
        "\n",
        "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
        "\n",
        "history = dqn.fit(env, nb_steps=8000, visualize=False, verbose=2)\n",
        "\n",
        "# summarize the history for number  of episode steps\n",
        "plt.plot(history.history['nb_episode_steps'])\n",
        "plt.ylabel('nb_episode_steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.show()\n",
        "\n",
        "dqn.test(env, nb_episodes=20, visualize=False)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_45\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_43 (Flatten)        (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 16)                80        \n",
            "                                                                 \n",
            " dense_88 (Dense)            (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 8000 steps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   19/8000: episode: 1, duration: 3.264s, episode steps:  19, steps per second:   6, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.421 [0.000, 1.000],  loss: --, mae: --, mean_q: --, mean_eps: --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/rl/memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
            "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   28/8000: episode: 2, duration: 8.994s, episode steps:   9, steps per second:   1, episode reward:  9.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.222 [0.000, 1.000],  loss: 0.524706, mae: 0.540137, mean_q: 0.011674, mean_eps: 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/rl/memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
            "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   54/8000: episode: 3, duration: 0.436s, episode steps:  26, steps per second:  60, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.308 [0.000, 1.000],  loss: 0.424747, mae: 0.503564, mean_q: 0.121969, mean_eps: 0.100000\n",
            "   91/8000: episode: 4, duration: 0.665s, episode steps:  37, steps per second:  56, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.459 [0.000, 1.000],  loss: 0.306326, mae: 0.508106, mean_q: 0.314359, mean_eps: 0.100000\n",
            "  173/8000: episode: 5, duration: 1.406s, episode steps:  82, steps per second:  58, episode reward: 82.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 0.220062, mae: 0.567308, mean_q: 0.596579, mean_eps: 0.100000\n",
            "  233/8000: episode: 6, duration: 1.143s, episode steps:  60, steps per second:  52, episode reward: 60.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.483 [0.000, 1.000],  loss: 0.149047, mae: 0.693354, mean_q: 1.010806, mean_eps: 0.100000\n",
            "  264/8000: episode: 7, duration: 0.614s, episode steps:  31, steps per second:  50, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.484 [0.000, 1.000],  loss: 0.124581, mae: 0.800702, mean_q: 1.281349, mean_eps: 0.100000\n",
            "  289/8000: episode: 8, duration: 0.549s, episode steps:  25, steps per second:  46, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.440 [0.000, 1.000],  loss: 0.110524, mae: 0.874857, mean_q: 1.474797, mean_eps: 0.100000\n",
            "  330/8000: episode: 9, duration: 0.700s, episode steps:  41, steps per second:  59, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.439 [0.000, 1.000],  loss: 0.090160, mae: 0.963456, mean_q: 1.706603, mean_eps: 0.100000\n",
            "  356/8000: episode: 10, duration: 0.498s, episode steps:  26, steps per second:  52, episode reward: 26.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.423 [0.000, 1.000],  loss: 0.123524, mae: 1.094528, mean_q: 1.960294, mean_eps: 0.100000\n",
            "  381/8000: episode: 11, duration: 0.411s, episode steps:  25, steps per second:  61, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.360 [0.000, 1.000],  loss: 0.099533, mae: 1.169488, mean_q: 2.134762, mean_eps: 0.100000\n",
            "  445/8000: episode: 12, duration: 0.905s, episode steps:  64, steps per second:  71, episode reward: 64.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.438 [0.000, 1.000],  loss: 0.106329, mae: 1.333376, mean_q: 2.487887, mean_eps: 0.100000\n",
            "  467/8000: episode: 13, duration: 0.310s, episode steps:  22, steps per second:  71, episode reward: 22.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.409 [0.000, 1.000],  loss: 0.126048, mae: 1.486736, mean_q: 2.800783, mean_eps: 0.100000\n",
            "  505/8000: episode: 14, duration: 0.546s, episode steps:  38, steps per second:  70, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.395 [0.000, 1.000],  loss: 0.132135, mae: 1.606098, mean_q: 3.041554, mean_eps: 0.100000\n",
            "  542/8000: episode: 15, duration: 0.527s, episode steps:  37, steps per second:  70, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 0.151550, mae: 1.754481, mean_q: 3.309405, mean_eps: 0.100000\n",
            "  563/8000: episode: 16, duration: 0.313s, episode steps:  21, steps per second:  67, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.429 [0.000, 1.000],  loss: 0.146385, mae: 1.846802, mean_q: 3.530806, mean_eps: 0.100000\n",
            "  600/8000: episode: 17, duration: 0.584s, episode steps:  37, steps per second:  63, episode reward: 37.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.486 [0.000, 1.000],  loss: 0.148538, mae: 1.958101, mean_q: 3.749878, mean_eps: 0.100000\n",
            "  669/8000: episode: 18, duration: 1.415s, episode steps:  69, steps per second:  49, episode reward: 69.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.493 [0.000, 1.000],  loss: 0.142501, mae: 2.154166, mean_q: 4.154500, mean_eps: 0.100000\n",
            "  712/8000: episode: 19, duration: 0.959s, episode steps:  43, steps per second:  45, episode reward: 43.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.512 [0.000, 1.000],  loss: 0.184808, mae: 2.379652, mean_q: 4.564467, mean_eps: 0.100000\n",
            "  767/8000: episode: 20, duration: 0.982s, episode steps:  55, steps per second:  56, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.473 [0.000, 1.000],  loss: 0.180302, mae: 2.561878, mean_q: 4.961955, mean_eps: 0.100000\n",
            "  809/8000: episode: 21, duration: 0.731s, episode steps:  42, steps per second:  57, episode reward: 42.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 0.168984, mae: 2.753744, mean_q: 5.390101, mean_eps: 0.100000\n",
            "  847/8000: episode: 22, duration: 0.576s, episode steps:  38, steps per second:  66, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 0.248508, mae: 2.904933, mean_q: 5.623265, mean_eps: 0.100000\n",
            "  922/8000: episode: 23, duration: 1.393s, episode steps:  75, steps per second:  54, episode reward: 75.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 0.239403, mae: 3.113479, mean_q: 6.065963, mean_eps: 0.100000\n",
            "  972/8000: episode: 24, duration: 0.911s, episode steps:  50, steps per second:  55, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 0.246381, mae: 3.332330, mean_q: 6.522060, mean_eps: 0.100000\n",
            " 1000/8000: episode: 25, duration: 0.411s, episode steps:  28, steps per second:  68, episode reward: 28.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 0.219995, mae: 3.485254, mean_q: 6.874854, mean_eps: 0.100000\n",
            " 1013/8000: episode: 26, duration: 0.186s, episode steps:  13, steps per second:  70, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.538 [0.000, 1.000],  loss: 0.158121, mae: 3.582165, mean_q: 7.126917, mean_eps: 0.100000\n",
            " 1028/8000: episode: 27, duration: 0.250s, episode steps:  15, steps per second:  60, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 0.242791, mae: 3.640309, mean_q: 7.193135, mean_eps: 0.100000\n",
            " 1038/8000: episode: 28, duration: 0.217s, episode steps:  10, steps per second:  46, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.700 [0.000, 1.000],  loss: 0.400608, mae: 3.730382, mean_q: 7.301094, mean_eps: 0.100000\n",
            " 1053/8000: episode: 29, duration: 0.311s, episode steps:  15, steps per second:  48, episode reward: 15.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.667 [0.000, 1.000],  loss: 0.562579, mae: 3.784424, mean_q: 7.377556, mean_eps: 0.100000\n",
            " 1067/8000: episode: 30, duration: 0.255s, episode steps:  14, steps per second:  55, episode reward: 14.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.643 [0.000, 1.000],  loss: 0.388140, mae: 3.852654, mean_q: 7.556523, mean_eps: 0.100000\n",
            " 1077/8000: episode: 31, duration: 0.197s, episode steps:  10, steps per second:  51, episode reward: 10.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.600 [0.000, 1.000],  loss: 0.444981, mae: 3.906704, mean_q: 7.691325, mean_eps: 0.100000\n",
            " 1090/8000: episode: 32, duration: 0.216s, episode steps:  13, steps per second:  60, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 0.626542, mae: 3.958379, mean_q: 7.660735, mean_eps: 0.100000\n",
            " 1122/8000: episode: 33, duration: 0.462s, episode steps:  32, steps per second:  69, episode reward: 32.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 0.873445, mae: 4.079582, mean_q: 7.747256, mean_eps: 0.100000\n",
            " 1149/8000: episode: 34, duration: 0.449s, episode steps:  27, steps per second:  60, episode reward: 27.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.556 [0.000, 1.000],  loss: 0.766497, mae: 4.156694, mean_q: 7.954491, mean_eps: 0.100000\n",
            " 1169/8000: episode: 35, duration: 0.515s, episode steps:  20, steps per second:  39, episode reward: 20.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.550 [0.000, 1.000],  loss: 0.614850, mae: 4.214898, mean_q: 8.190656, mean_eps: 0.100000\n",
            " 1194/8000: episode: 36, duration: 0.534s, episode steps:  25, steps per second:  47, episode reward: 25.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 0.600065, mae: 4.294534, mean_q: 8.369883, mean_eps: 0.100000\n",
            " 1218/8000: episode: 37, duration: 0.345s, episode steps:  24, steps per second:  70, episode reward: 24.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.805350, mae: 4.434208, mean_q: 8.577725, mean_eps: 0.100000\n",
            " 1239/8000: episode: 38, duration: 0.304s, episode steps:  21, steps per second:  69, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.524 [0.000, 1.000],  loss: 0.711534, mae: 4.514940, mean_q: 8.684896, mean_eps: 0.100000\n",
            " 1258/8000: episode: 39, duration: 0.310s, episode steps:  19, steps per second:  61, episode reward: 19.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 0.907007, mae: 4.587096, mean_q: 8.911264, mean_eps: 0.100000\n",
            " 1291/8000: episode: 40, duration: 0.709s, episode steps:  33, steps per second:  47, episode reward: 33.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.485 [0.000, 1.000],  loss: 0.803643, mae: 4.673114, mean_q: 9.025262, mean_eps: 0.100000\n",
            " 1321/8000: episode: 41, duration: 0.542s, episode steps:  30, steps per second:  55, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.500 [0.000, 1.000],  loss: 0.764723, mae: 4.768435, mean_q: 9.206950, mean_eps: 0.100000\n",
            " 1344/8000: episode: 42, duration: 0.351s, episode steps:  23, steps per second:  65, episode reward: 23.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 0.933931, mae: 4.883842, mean_q: 9.444871, mean_eps: 0.100000\n",
            " 1385/8000: episode: 43, duration: 0.632s, episode steps:  41, steps per second:  65, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.537 [0.000, 1.000],  loss: 0.879636, mae: 4.984996, mean_q: 9.665339, mean_eps: 0.100000\n",
            " 1402/8000: episode: 44, duration: 0.264s, episode steps:  17, steps per second:  64, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.588 [0.000, 1.000],  loss: 1.432050, mae: 5.136274, mean_q: 9.798856, mean_eps: 0.100000\n",
            " 1418/8000: episode: 45, duration: 0.234s, episode steps:  16, steps per second:  68, episode reward: 16.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.625 [0.000, 1.000],  loss: 0.878613, mae: 5.110284, mean_q: 9.879433, mean_eps: 0.100000\n",
            " 1431/8000: episode: 46, duration: 0.211s, episode steps:  13, steps per second:  62, episode reward: 13.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.615 [0.000, 1.000],  loss: 1.194577, mae: 5.216385, mean_q: 10.056012, mean_eps: 0.100000\n",
            " 1448/8000: episode: 47, duration: 0.282s, episode steps:  17, steps per second:  60, episode reward: 17.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 1.502193, mae: 5.290425, mean_q: 10.052621, mean_eps: 0.100000\n",
            " 1469/8000: episode: 48, duration: 0.325s, episode steps:  21, steps per second:  65, episode reward: 21.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.571 [0.000, 1.000],  loss: 1.620875, mae: 5.328230, mean_q: 10.112063, mean_eps: 0.100000\n",
            " 1522/8000: episode: 49, duration: 1.000s, episode steps:  53, steps per second:  53, episode reward: 53.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.509 [0.000, 1.000],  loss: 0.945669, mae: 5.375254, mean_q: 10.451795, mean_eps: 0.100000\n",
            " 1592/8000: episode: 50, duration: 1.254s, episode steps:  70, steps per second:  56, episode reward: 70.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.557 [0.000, 1.000],  loss: 1.220418, mae: 5.597126, mean_q: 10.814997, mean_eps: 0.100000\n",
            " 1660/8000: episode: 51, duration: 1.389s, episode steps:  68, steps per second:  49, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 1.125727, mae: 5.786907, mean_q: 11.227366, mean_eps: 0.100000\n",
            " 1711/8000: episode: 52, duration: 1.060s, episode steps:  51, steps per second:  48, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.549 [0.000, 1.000],  loss: 1.048981, mae: 5.942208, mean_q: 11.571077, mean_eps: 0.100000\n",
            " 1770/8000: episode: 53, duration: 1.095s, episode steps:  59, steps per second:  54, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.559 [0.000, 1.000],  loss: 1.473902, mae: 6.135297, mean_q: 11.851129, mean_eps: 0.100000\n",
            " 1838/8000: episode: 54, duration: 1.026s, episode steps:  68, steps per second:  66, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.471 [0.000, 1.000],  loss: 1.677317, mae: 6.293076, mean_q: 12.105553, mean_eps: 0.100000\n",
            " 1912/8000: episode: 55, duration: 1.125s, episode steps:  74, steps per second:  66, episode reward: 74.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.541 [0.000, 1.000],  loss: 1.626822, mae: 6.495965, mean_q: 12.590429, mean_eps: 0.100000\n",
            " 1942/8000: episode: 56, duration: 0.456s, episode steps:  30, steps per second:  66, episode reward: 30.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 1.213697, mae: 6.596680, mean_q: 12.886324, mean_eps: 0.100000\n",
            " 1992/8000: episode: 57, duration: 0.800s, episode steps:  50, steps per second:  62, episode reward: 50.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.540 [0.000, 1.000],  loss: 1.786340, mae: 6.730386, mean_q: 13.036598, mean_eps: 0.100000\n",
            " 2047/8000: episode: 58, duration: 0.938s, episode steps:  55, steps per second:  59, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.527 [0.000, 1.000],  loss: 1.732545, mae: 6.875081, mean_q: 13.347683, mean_eps: 0.100000\n",
            " 2113/8000: episode: 59, duration: 1.218s, episode steps:  66, steps per second:  54, episode reward: 66.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.530 [0.000, 1.000],  loss: 1.525199, mae: 7.040447, mean_q: 13.805329, mean_eps: 0.100000\n",
            " 2174/8000: episode: 60, duration: 1.001s, episode steps:  61, steps per second:  61, episode reward: 61.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.541 [0.000, 1.000],  loss: 1.569349, mae: 7.222356, mean_q: 14.162124, mean_eps: 0.100000\n",
            " 2213/8000: episode: 61, duration: 0.789s, episode steps:  39, steps per second:  49, episode reward: 39.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.487 [0.000, 1.000],  loss: 1.719467, mae: 7.356610, mean_q: 14.425870, mean_eps: 0.100000\n",
            " 2269/8000: episode: 62, duration: 1.435s, episode steps:  56, steps per second:  39, episode reward: 56.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.536 [0.000, 1.000],  loss: 1.842782, mae: 7.463594, mean_q: 14.602456, mean_eps: 0.100000\n",
            " 2310/8000: episode: 63, duration: 0.944s, episode steps:  41, steps per second:  43, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.537 [0.000, 1.000],  loss: 1.421699, mae: 7.594543, mean_q: 14.946790, mean_eps: 0.100000\n",
            " 2385/8000: episode: 64, duration: 1.798s, episode steps:  75, steps per second:  42, episode reward: 75.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 2.066970, mae: 7.782010, mean_q: 15.222962, mean_eps: 0.100000\n",
            " 2416/8000: episode: 65, duration: 0.709s, episode steps:  31, steps per second:  44, episode reward: 31.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.548 [0.000, 1.000],  loss: 1.935125, mae: 7.932127, mean_q: 15.519814, mean_eps: 0.100000\n",
            " 2484/8000: episode: 66, duration: 1.658s, episode steps:  68, steps per second:  41, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 2.476517, mae: 8.081258, mean_q: 15.692053, mean_eps: 0.100000\n",
            " 2549/8000: episode: 67, duration: 1.123s, episode steps:  65, steps per second:  58, episode reward: 65.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.554 [0.000, 1.000],  loss: 1.878823, mae: 8.213520, mean_q: 16.114344, mean_eps: 0.100000\n",
            " 2619/8000: episode: 68, duration: 1.102s, episode steps:  70, steps per second:  64, episode reward: 70.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.457 [0.000, 1.000],  loss: 1.759914, mae: 8.385977, mean_q: 16.553084, mean_eps: 0.100000\n",
            " 2678/8000: episode: 69, duration: 0.859s, episode steps:  59, steps per second:  69, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.458 [0.000, 1.000],  loss: 2.513534, mae: 8.573362, mean_q: 16.764866, mean_eps: 0.100000\n",
            " 2744/8000: episode: 70, duration: 0.989s, episode steps:  66, steps per second:  67, episode reward: 66.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 2.098074, mae: 8.734727, mean_q: 17.184999, mean_eps: 0.100000\n",
            " 2812/8000: episode: 71, duration: 1.519s, episode steps:  68, steps per second:  45, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 1.777728, mae: 8.892977, mean_q: 17.557657, mean_eps: 0.100000\n",
            " 2850/8000: episode: 72, duration: 0.928s, episode steps:  38, steps per second:  41, episode reward: 38.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.553 [0.000, 1.000],  loss: 2.952167, mae: 9.092498, mean_q: 17.754431, mean_eps: 0.100000\n",
            " 2901/8000: episode: 73, duration: 1.084s, episode steps:  51, steps per second:  47, episode reward: 51.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.549 [0.000, 1.000],  loss: 2.378598, mae: 9.167298, mean_q: 18.029493, mean_eps: 0.100000\n",
            " 2955/8000: episode: 74, duration: 1.046s, episode steps:  54, steps per second:  52, episode reward: 54.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.537 [0.000, 1.000],  loss: 3.081175, mae: 9.340893, mean_q: 18.237344, mean_eps: 0.100000\n",
            " 3004/8000: episode: 75, duration: 0.699s, episode steps:  49, steps per second:  70, episode reward: 49.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.531 [0.000, 1.000],  loss: 2.300947, mae: 9.437764, mean_q: 18.575767, mean_eps: 0.100000\n",
            " 3127/8000: episode: 76, duration: 2.234s, episode steps: 123, steps per second:  55, episode reward: 123.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 2.275024, mae: 9.654492, mean_q: 19.044026, mean_eps: 0.100000\n",
            " 3238/8000: episode: 77, duration: 2.475s, episode steps: 111, steps per second:  45, episode reward: 111.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.568 [0.000, 1.000],  loss: 2.965719, mae: 9.993225, mean_q: 19.608764, mean_eps: 0.100000\n",
            " 3359/8000: episode: 78, duration: 2.526s, episode steps: 121, steps per second:  48, episode reward: 121.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.554 [0.000, 1.000],  loss: 2.994618, mae: 10.132931, mean_q: 19.937635, mean_eps: 0.100000\n",
            " 3470/8000: episode: 79, duration: 2.598s, episode steps: 111, steps per second:  43, episode reward: 111.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.559 [0.000, 1.000],  loss: 3.054525, mae: 10.223990, mean_q: 20.152316, mean_eps: 0.100000\n",
            " 3550/8000: episode: 80, duration: 1.416s, episode steps:  80, steps per second:  56, episode reward: 80.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.525 [0.000, 1.000],  loss: 2.439163, mae: 10.259728, mean_q: 20.301841, mean_eps: 0.100000\n",
            " 3622/8000: episode: 81, duration: 1.675s, episode steps:  72, steps per second:  43, episode reward: 72.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 2.238278, mae: 10.543878, mean_q: 20.906835, mean_eps: 0.100000\n",
            " 3677/8000: episode: 82, duration: 1.446s, episode steps:  55, steps per second:  38, episode reward: 55.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.545 [0.000, 1.000],  loss: 3.253317, mae: 10.776298, mean_q: 21.308679, mean_eps: 0.100000\n",
            " 3808/8000: episode: 83, duration: 2.744s, episode steps: 131, steps per second:  48, episode reward: 131.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.443 [0.000, 1.000],  loss: 3.088846, mae: 11.000796, mean_q: 21.753601, mean_eps: 0.100000\n",
            " 3867/8000: episode: 84, duration: 1.196s, episode steps:  59, steps per second:  49, episode reward: 59.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.559 [0.000, 1.000],  loss: 3.725546, mae: 11.420370, mean_q: 22.584314, mean_eps: 0.100000\n",
            " 3977/8000: episode: 85, duration: 1.728s, episode steps: 110, steps per second:  64, episode reward: 110.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.564 [0.000, 1.000],  loss: 3.987449, mae: 11.518918, mean_q: 22.667950, mean_eps: 0.100000\n",
            " 4018/8000: episode: 86, duration: 0.658s, episode steps:  41, steps per second:  62, episode reward: 41.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.561 [0.000, 1.000],  loss: 3.194656, mae: 11.579116, mean_q: 22.864818, mean_eps: 0.100000\n",
            " 4086/8000: episode: 87, duration: 1.456s, episode steps:  68, steps per second:  47, episode reward: 68.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 2.578988, mae: 11.621083, mean_q: 23.016123, mean_eps: 0.100000\n",
            " 4199/8000: episode: 88, duration: 2.279s, episode steps: 113, steps per second:  50, episode reward: 113.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.558 [0.000, 1.000],  loss: 4.476217, mae: 11.910821, mean_q: 23.412743, mean_eps: 0.100000\n",
            " 4369/8000: episode: 89, duration: 3.187s, episode steps: 170, steps per second:  53, episode reward: 170.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.476 [0.000, 1.000],  loss: 4.602248, mae: 12.045211, mean_q: 23.675034, mean_eps: 0.100000\n",
            " 4440/8000: episode: 90, duration: 1.367s, episode steps:  71, steps per second:  52, episode reward: 71.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.465 [0.000, 1.000],  loss: 3.285871, mae: 12.321090, mean_q: 24.405596, mean_eps: 0.100000\n",
            " 4562/8000: episode: 91, duration: 2.123s, episode steps: 122, steps per second:  57, episode reward: 122.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.549 [0.000, 1.000],  loss: 4.646311, mae: 12.487803, mean_q: 24.584718, mean_eps: 0.100000\n",
            " 4762/8000: episode: 92, duration: 4.048s, episode steps: 200, steps per second:  49, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 4.742721, mae: 12.666734, mean_q: 25.017113, mean_eps: 0.100000\n",
            " 4885/8000: episode: 93, duration: 2.079s, episode steps: 123, steps per second:  59, episode reward: 123.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.463 [0.000, 1.000],  loss: 3.946900, mae: 13.011724, mean_q: 25.825620, mean_eps: 0.100000\n",
            " 5011/8000: episode: 94, duration: 2.292s, episode steps: 126, steps per second:  55, episode reward: 126.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.532 [0.000, 1.000],  loss: 4.320570, mae: 13.276404, mean_q: 26.288985, mean_eps: 0.100000\n",
            " 5148/8000: episode: 95, duration: 1.910s, episode steps: 137, steps per second:  72, episode reward: 137.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.533 [0.000, 1.000],  loss: 4.184520, mae: 13.433032, mean_q: 26.615249, mean_eps: 0.100000\n",
            " 5288/8000: episode: 96, duration: 2.783s, episode steps: 140, steps per second:  50, episode reward: 140.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 4.383952, mae: 13.513079, mean_q: 26.785884, mean_eps: 0.100000\n",
            " 5449/8000: episode: 97, duration: 3.330s, episode steps: 161, steps per second:  48, episode reward: 161.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.528 [0.000, 1.000],  loss: 4.619278, mae: 13.721297, mean_q: 27.132010, mean_eps: 0.100000\n",
            " 5570/8000: episode: 98, duration: 1.800s, episode steps: 121, steps per second:  67, episode reward: 121.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.537 [0.000, 1.000],  loss: 4.078060, mae: 13.953051, mean_q: 27.700203, mean_eps: 0.100000\n",
            " 5712/8000: episode: 99, duration: 2.132s, episode steps: 142, steps per second:  67, episode reward: 142.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.535 [0.000, 1.000],  loss: 5.210052, mae: 14.002823, mean_q: 27.745718, mean_eps: 0.100000\n",
            " 5840/8000: episode: 100, duration: 2.160s, episode steps: 128, steps per second:  59, episode reward: 128.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.539 [0.000, 1.000],  loss: 5.212309, mae: 14.168494, mean_q: 28.072790, mean_eps: 0.100000\n",
            " 5994/8000: episode: 101, duration: 2.615s, episode steps: 154, steps per second:  59, episode reward: 154.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.526 [0.000, 1.000],  loss: 5.111608, mae: 14.318101, mean_q: 28.400548, mean_eps: 0.100000\n",
            " 6153/8000: episode: 102, duration: 2.562s, episode steps: 159, steps per second:  62, episode reward: 159.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 4.127218, mae: 14.511913, mean_q: 28.907809, mean_eps: 0.100000\n",
            " 6263/8000: episode: 103, duration: 1.576s, episode steps: 110, steps per second:  70, episode reward: 110.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 4.569267, mae: 14.791883, mean_q: 29.474398, mean_eps: 0.100000\n",
            " 6463/8000: episode: 104, duration: 3.419s, episode steps: 200, steps per second:  58, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 4.944453, mae: 15.133920, mean_q: 30.094181, mean_eps: 0.100000\n",
            " 6638/8000: episode: 105, duration: 2.602s, episode steps: 175, steps per second:  67, episode reward: 175.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.520 [0.000, 1.000],  loss: 5.274141, mae: 15.291953, mean_q: 30.398299, mean_eps: 0.100000\n",
            " 6778/8000: episode: 106, duration: 1.977s, episode steps: 140, steps per second:  71, episode reward: 140.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.529 [0.000, 1.000],  loss: 5.063623, mae: 15.567932, mean_q: 30.947670, mean_eps: 0.100000\n",
            " 6978/8000: episode: 107, duration: 2.752s, episode steps: 200, steps per second:  73, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 3.882870, mae: 15.759525, mean_q: 31.494128, mean_eps: 0.100000\n",
            " 7111/8000: episode: 108, duration: 1.920s, episode steps: 133, steps per second:  69, episode reward: 133.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.534 [0.000, 1.000],  loss: 5.543297, mae: 16.014947, mean_q: 31.854369, mean_eps: 0.100000\n",
            " 7285/8000: episode: 109, duration: 2.510s, episode steps: 174, steps per second:  69, episode reward: 174.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.517 [0.000, 1.000],  loss: 5.612476, mae: 16.278243, mean_q: 32.424284, mean_eps: 0.100000\n",
            " 7485/8000: episode: 110, duration: 2.923s, episode steps: 200, steps per second:  68, episode reward: 200.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.515 [0.000, 1.000],  loss: 5.841666, mae: 16.527725, mean_q: 32.951759, mean_eps: 0.100000\n",
            " 7652/8000: episode: 111, duration: 2.400s, episode steps: 167, steps per second:  70, episode reward: 167.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.521 [0.000, 1.000],  loss: 6.393217, mae: 16.803579, mean_q: 33.450225, mean_eps: 0.100000\n",
            " 7830/8000: episode: 112, duration: 2.587s, episode steps: 178, steps per second:  69, episode reward: 178.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.522 [0.000, 1.000],  loss: 4.677434, mae: 17.005956, mean_q: 33.982452, mean_eps: 0.100000\n",
            " 7940/8000: episode: 113, duration: 1.577s, episode steps: 110, steps per second:  70, episode reward: 110.000, mean reward:  1.000 [ 1.000,  1.000], mean action: 0.455 [0.000, 1.000],  loss: 4.900972, mae: 17.139281, mean_q: 34.322534, mean_eps: 0.100000\n",
            "done, took 152.448 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 166.000, steps: 166\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 166.000, steps: 166\n",
            "Episode 4: reward: 183.000, steps: 183\n",
            "Episode 5: reward: 189.000, steps: 189\n",
            "Episode 6: reward: 171.000, steps: 171\n",
            "Episode 7: reward: 172.000, steps: 172\n",
            "Episode 8: reward: 170.000, steps: 170\n",
            "Episode 9: reward: 174.000, steps: 174\n",
            "Episode 10: reward: 190.000, steps: 190\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 171.000, steps: 171\n",
            "Episode 13: reward: 158.000, steps: 158\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 178.000, steps: 178\n",
            "Episode 16: reward: 179.000, steps: 179\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 184.000, steps: 184\n",
            "Episode 20: reward: 184.000, steps: 184\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb170954dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    }
  ]
}